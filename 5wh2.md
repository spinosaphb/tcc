## <center> Análise de interoperabilidade e desempenho do ONNX runtime em modelos de redes neurais em diferentes plataformas

## <center> Pedro Spinosa
____

### 1. Contextualização do trabalho

- Análise de interoperabilidade e desempenho do ONNX runtime em comparação com outros formatos de modelos de redes neurais em diferentes plataformas.


### 2. Justificativa
- Avaliar como o ONNX se compara a outros formatos de modelos de redes neurais em termos de interoperabilidade e desempenho em diferentes plataformas, e identificar pontos de melhoria para a utilização do ONNX em modelos no ambiente de produção.

### 3. Como a situação pode ser resolvida hoje?

- É possível resolver através do uso de diferentes frameworks de deep learning, como TensorFlow, PyTorch, Caffe e MXNet, que possuem suporte para a conversão de modelos para o formato ONNX. Entretanto, cada uma dessas soluções apresenta limitações. Por exemplo, o uso de diferentes frameworks de deep learning pode gerar modelos de diferentes tamanhos e formatos. Além disso, a interoperabilidade entre diferentes frameworks pode ser prejudicada por diferenças nas implementações de operações e algoritmos.

- O ONNX runtime oferece uma solução mais unificada e escalável para a execução de modelos ONNX em diferentes plataformas. No entanto, o desempenho do ONNX runtime pode variar dependendo do hardware e do tipo de modelo sendo executado.

- É importante explorar alternativas que possam oferecer escalabilidade e interoperabilidade de modelos de redes neurais. Como o desenvolvimento de técnicas de conversão de modelos baseadas em redes neurais que sejam capazes de lidar com modelos de diferentes arquiteturas e frameworks.

### 4. Quando e onde?
- Engenheiros de Machine Learning e Data Scientists que trabalham com modelos de redes neurais em diferentes plataformas e precisam colocar esses serviços em produção.

### 5. Quanto?
- pass

### 6 Conceitos

- Os três princiais conceitos que serão abordados neste trabalho são:

    - ONNX: é um formato de modelo de rede neural desenvolvido pela Microsoft e apoiado por vários parceiros da indústria, incluindo Facebook, Amazon. O objetivo do ONNX é permitir a interoperabilidade entre diferentes frameworks de deep learning.

    - ONNX runtime: é uma biblioteca que permite a execução de modelos ONNX em diferentes plataformas, incluindo CPUs, GPUs e TPU.

    - Interoperabilidade: No contexto de modelos de rede neural, a interoperabilidade é importante porque permite que os modelos sejam compartilhados e executados em diferentes frameworks e plataformas, sem a necessidade de conversão manual.